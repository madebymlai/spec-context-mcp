# Embeddings (required for semantic search)
EMBEDDING_PROVIDER=voyageai
EMBEDDING_API_KEY=
EMBEDDING_MODEL=
EMBEDDING_BASE_URL=
EMBEDDING_RERANK_MODEL=
EMBEDDING_RERANK_URL=
EMBEDDING_RERANK_FORMAT=auto
EMBEDDING_RERANK_BATCH_SIZE=
# EMBEDDING_DIMENSION is currently ignored (model defines dimensions)
EMBEDDING_DIMENSION=

# VoyageAI alias (optional alternative to EMBEDDING_API_KEY for voyageai provider)
VOYAGEAI_API_KEY=

# OpenAI API key for LLM reasoning (not used for embeddings)
OPENAI_API_KEY=

# Optional
# Python executable for ChunkHound.
# Leave unset to let spec-context choose a local `.venv/bin/python` if present.
# Set this only if you've installed the Python deps into that interpreter/venv.
# CHUNKHOUND_PYTHON=python3
DASHBOARD_URL=http://localhost:3000

# Required only for dashboard AI review
OPENROUTER_API_KEY=

# Disable dashboard npm version check (optional)
SPEC_CONTEXT_DISABLE_VERSION_CHECK=false

# ChunkHound LLM for deep research
# Options: openai, ollama, claude-code-cli, codex-cli, gemini, anthropic, opencode-cli
CHUNKHOUND_LLM_PROVIDER=claude-code-cli
CHUNKHOUND_LLM_API_KEY=
CHUNKHOUND_LLM_BASE_URL=
CHUNKHOUND_LLM_UTILITY_MODEL=
CHUNKHOUND_LLM_SYNTHESIS_MODEL=

# ChunkHound runtime tuning (optional)
CHUNKHOUND_EMBED_SWEEP_SECONDS=300
CHUNKHOUND_EMBED_SWEEP_BACKOFF_SECONDS=30
CHUNKHOUND_FILE_QUEUE_MAXSIZE=2000
CHUNKHOUND_FILE_QUEUE_DRAIN_SECONDS=1.0

# Discipline mode: full (TDD+reviews), standard (reviews), minimal (verification only)
SPEC_CONTEXT_DISCIPLINE=full

# CLI dispatch for multi-LLM orchestration (optional)
# Set to CLI command to dispatch roles to different LLMs
# SPEC_CONTEXT_IMPLEMENTER=claude
# SPEC_CONTEXT_REVIEWER=codex
# SPEC_CONTEXT_BRAINSTORM=gemini
